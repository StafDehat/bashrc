#!/bin/bash

#
# Upload a file to Cloud Files.  If it's over 4GB, split into 1GB chunks.

. $BASHRC_BASE/bashrc/errors.bash

function usage() {
  echo "Usage: brc-files-uploadfile [-h] [-a BRC_AUTHTOKEN] [-r BRC_REGION] \\"
  echo "                            [-t BRC_TENANTID] [-v BRC_VAULTNAME] \\"
  echo "                            -f LOCALFILE -c CONTAINER \\"
  echo "                            [-n OBJECTNAME]"
  echo "Example:"
  echo "  # brc-files-uploadfile -a 1a2b3c4d5e6f7g8h9i0j \\"
  echo "                         -t 123456 \\"
  echo "                         -v MossoCloudFS_199f2dd2-e293-11e3-87ea-6f46a026e216 \\"
  echo "                         -r dfw \\"
  echo "                         -f /home/user/pbjt.jpg \\"
  echo "                         -c jpegs"
  echo "Arguments:"
  echo "  -a X	Authentication token.  This can be set via the environment"
  echo "        variable BRC_AUTHTOKEN instead of as an argument."
  echo "  -c X  Name of Cloud Files container in which to store file."
  echo "  -f X  Path to local file to be uploaded."
  echo "  -h	Print this help"
  echo "  -n X  Optional.  Filename to use in Cloud Files.  If excluded,"
  echo "        name in Cloud Files will match local filename."
  echo "  -r X  Region.  Examples: iad, dfw, ord, syd.  This can be set via"
  echo "        the environment variable BRC_REGION instead of as an"
  echo "        argument."
  echo "  -v X  Vault name for this account.  This can be set via the environment"
  echo "        variable BRC_VAULTNAME instead of as an argument."
}

USAGEFLAG=0
while getopts ":a:c:f:hn:r:v:" arg; do
  case $arg in
    a) BRC_AUTHTOKEN=$OPTARG;;
    c) CONTAINER="$OPTARG";;
    f) LOCALFILE="$OPTARG";;
    h) usage && exit 0;;
    n) OBJECTNAME="$OPTARG";;
    r) BRC_REGION=$OPTARG;;
    v) BRC_VAULTNAME=$OPTARG;;
    :) echo "ERROR: Option -$OPTARG requires an argument."
       USAGEFLAG=1;;
    *) echo "ERROR: Invalid option: -$OPTARG"
       USAGEFLAG=1;;
  esac
done #End arguments
shift $(($OPTIND - 1))

for ARG in BRC_AUTHTOKEN BRC_REGION BRC_VAULTNAME; do
  if [ -z "${!ARG}" ]; then
    echo "ERROR: Must define ${!ARG} in environment or argument"
    USAGEFLAG=1
  fi
done
for ARG in CONTAINER LOCALFILE; do
  if [ -z "${!ARG}" ]; then
    echo "ERROR: Must define ${!ARG} as argument"
    USAGEFLAG=1
  fi
done
if [ $USAGEFLAG -ne 0 ]; then
  usage && exit 1
fi
if [ ! -f "$LOCALFILE" ]; then
  echo "ERROR: Can not access $LOCALFILE - does it exist?"
  exit 1
fi

FILES_ENDPOINT=$( $BRCUTIL/brc-util-filesendpoint -r $BRC_REGION )
#CDN_ENDPOINT=$( $BRCUTIL/brc-util-cdnendpoint -r $BRC_REGION )

if [ -z "$OBJECTNAME" ]; then
  OBJECTNAME=$( basename "$LOCALFILE" )
fi


function uploadSmallFile() {
  local FILE="$1"
  local CFNAME="$2"
  DATA=$( curl -I --write-out \\n%{http_code} --silent --output - \
               $FILES_ENDPOINT/$BRC_VAULTNAME/"$CONTAINER"/"$CFNAME" \
               -X PUT \
               -T "$FILE" \
               -H "X-Auth-Token: $BRC_AUTHTOKEN" \
            2>/dev/null )
  RETVAL=$?
  CODE=$( echo "$DATA" | tail -n 1 )
  # Check for failed API call
  if [ $RETVAL -ne 0 ]; then
    errorcurlfail
  elif ! grep -qE '^2..$' <<<$CODE; then
    errornot200 $CODE $( echo "$DATA" | head -n -1 )
  fi
  # Print the md5sum etag
  # We'll test the value outside this function
  # Trying to test inside this function puts us in named-pipe hell, introduces deadlock,
  #   and/or forces us to run the 'dd' twice.
  echo "$DATA" | sed -n 's/^\s*Etag:\s*//p'
}


function uploadLargeFile() {
  local FILE="$1"
  local CFNAME="$2"
  local SIZE=$( du -B 1G "$FILE" | awk '{print $1}' )
  local PIPE1="/tmp/bashrc.pipe1"
  local PIPE2="/tmp/bashrc.pipe2"

  # Upload all the file segments, 1G at a time
  mkfifo $PIPE1 $PIPE2
  for COUNT in $( seq -w 0 $(( $SIZE - 1 )) ); do
    # Retry loop - try 10 times
    for x in `seq 1 10`; do
      echo "Creating object '${CFNAME}-$COUNT'."
      # bs=4096 -- Attempt to optimize read speeds by matching block size on drive architecture
      # count=262144 == 1G/4096 -- Read 1G
      # skip=262144 * $COUNT -- Skip previously-read 1G chunks
      dd if="$FILE" bs=4k count=262144 seek=$(( 262144 * $COUNT )) 2>/dev/null \
        | tee $PIPE1 \
        | md5sum | awk '{print $1}' > $PIPE2 &
      local ETAG=$( uploadSmallFile $PIPE1 \
                                    "${CFNAME}"-$COUNT )
      MD5=$( cat $PIPE2 )
      # If segment uploaded successfully, break the x(1-10) retry loop
      # Stay in the COUNT loop.  ie: Do the next segment.
      if grep -q "$MD5" <<<$ETAG; then
        break
      fi
      # MD5 error - loop to retry
      continue
    done #End for x(1-10)
  done #End for COUNT
  rm -f $PIPE1 $PIPE2

  # Create a dynamic manifest file
  echo "Creating manifest object '$CFNAME'."
  DATA=$( curl --write-out \\n%{http_code} --silent --output - \
               $FILES_ENDPOINT/$BRC_VAULTNAME/"$CONTAINER"/"$CFNAME" \
               -T /dev/null \
               -X PUT \
               -H "X-Auth-Token: $BRC_AUTHTOKEN" \
               -H "X-Object-Manifest: $CONTAINER/${CFNAME}-" \
            2>/dev/null )
  RETVAL=$?
  CODE=$( echo "$DATA" | tail -n 1 )
  # Check for failed API call
  if [ $RETVAL -ne 0 ]; then
    errorcurlfail
  elif ! grep -qE '^2..$' <<<$CODE; then
    errornot200 $CODE $( echo "$DATA" | head -n -1 )
  fi
}


#
# Test the source file.
# If > 4G then split & upload each piece individually, then create a dynamic manifest
# http://docs.rackspace.com/files/api/v1/cf-devguide/content/Large_Object_Creation-d1e2019.html
MAXSIZE=$(( 5 * 1024 * 1024 * 1024 ))
if [ $( du -B 1G "$LOCALFILE" | awk '{print $1}' ) -lt $MAXSIZE ]; then
  # Retry loop - try <=10 times
  for x in `seq 1 10`; do
    echo "Creating object '$OBJECTNAME'."
    MD5=$( md5sum "$LOCALFILE" | awk '{print $1}' )
    ETAG=$( uploadSmallFile $LOCALFILE "$OBJECTNAME" )
    # If segment uploaded successfully, break the x(1-10) retry loop
    # Stay in the COUNT loop.  ie: Do the next segment.
    if grep -q "$MD5" <<<$ETAG; then
      break
    fi
    # MD5 error - loop to retry
    continue
  done
else
  echo "Object '$OBJECTNAME' >4G.  Splitting into 1G segments."
  uploadLargeFile "$LOCALFILE" "$OBJECTNAME"
fi

exit 0

